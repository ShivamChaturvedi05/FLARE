{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a15dcbf-d329-4394-8b3f-3a860fe932eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, auc\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "print(\"All libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb682cc0-7258-4907-90d9-8ea8feea2941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing functions defined.\n"
     ]
    }
   ],
   "source": [
    "def load_fits_image(filepath):\n",
    "    try:\n",
    "        with fits.open(filepath) as hdul:\n",
    "            image_data = hdul[0].data\n",
    "            header = hdul[0].header\n",
    "            \n",
    "            if image_data is not None:\n",
    "                image_data = image_data.astype(np.float32)\n",
    "            return image_data, header\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading FITS file {filepath}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def subtract_background(image_data):\n",
    "    if image_data is None:\n",
    "        return None\n",
    "    mean, median_bkg, stddev = sigma_clipped_stats(image_data, sigma=3.0)\n",
    "    return image_data - median_bkg\n",
    "\n",
    "def robust_scale_image(image_data):\n",
    "    if image_data is None:\n",
    "        return None\n",
    "    scaler = RobustScaler()\n",
    "    \n",
    "    pixels = image_data.flatten().reshape(-1, 1)\n",
    "    \n",
    "    scaled_pixels = scaler.fit_transform(pixels)\n",
    "    \n",
    "    return scaled_pixels.reshape(image_data.shape)\n",
    "\n",
    "def resize_image(image_data, target_size=(64, 64)):\n",
    "    if image_data is None:\n",
    "        return None\n",
    "    return cv2.resize(image_data, target_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "print(\"Preprocessing functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d549ccde-037c-4605-b637-1c11a2b4e471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation pipeline defined.\n"
     ]
    }
   ],
   "source": [
    "# Define a sequential model for data augmentation\n",
    "data_augmentation_pipeline = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),  # Randomly flip images horizontally and vertically\n",
    "    layers.RandomRotation(0.5),  # Corresponds to 180 degrees\n",
    "    # Small translations and gaussian noise can also be added here\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "print(\"Data augmentation pipeline defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9661d046-4d5c-474c-bbbc-14068c7c04f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading real dataset files...\n",
      "Loaded 7215 total images.\n",
      "Processing real image data... (This may take a minute)\n",
      "Data shape (X): (7215, 64, 64, 3)\n",
      "Labels shape (y): (7215,)\n",
      "Class distribution (0=Bogus, 1=Real): [3571 3644]\n",
      "Train shapes: X=(4617, 64, 64, 3), y=(4617,)\n",
      "Val shapes:   X=(1155, 64, 64, 3), y=(1155,)\n",
      "Test shapes:  X=(1443, 64, 64, 3), y=(1443,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # Make sure pandas is imported for reading CSV files\n",
    "\n",
    "# --- 1. Load the Real Data ---\n",
    "# Paths are set for your \"FLARE/dataset/\" folder structure\n",
    "ATLAS_IMG_PATH = 'dataset/ATLAS_images.npy'\n",
    "ATLAS_LBL_PATH = 'dataset/ATLAS_labels.csv'\n",
    "MEER_IMG_PATH  = 'dataset/MeerLICHT_images.npy'\n",
    "MEER_LBL_PATH  = 'dataset/MeerLICHT_labels.csv'\n",
    "PAN_IMG_PATH   = 'dataset/PANSTARRS_images.npy'\n",
    "PAN_LBL_PATH   = 'dataset/PANSTARRS_labels.csv'\n",
    "\n",
    "print(\"Loading real dataset files...\")\n",
    "try:\n",
    "    # Load image arrays\n",
    "    atlas_images = np.load(ATLAS_IMG_PATH)\n",
    "    meer_images = np.load(MEER_IMG_PATH)\n",
    "    pan_images = np.load(PAN_IMG_PATH)\n",
    "    \n",
    "    # Load label CSVs\n",
    "    atlas_labels_df = pd.read_csv(ATLAS_LBL_PATH)\n",
    "    meer_labels_df = pd.read_csv(MEER_LBL_PATH)\n",
    "    pan_labels_df = pd.read_csv(PAN_LBL_PATH)\n",
    "\n",
    "    # Combine all data into single arrays\n",
    "    X_raw = np.concatenate([atlas_images, meer_images, pan_images], axis=0)\n",
    "    labels_df = pd.concat([atlas_labels_df, meer_labels_df, pan_labels_df], ignore_index=True)\n",
    "    \n",
    "    print(f\"Loaded {len(X_raw)} total images.\")\n",
    "    \n",
    "    # --- Process Labels ---\n",
    "    LABEL_COLUMN = 'label' \n",
    "    \n",
    "    # Convert text labels \"Real\" / \"Bogus\" to 1 / 0\n",
    "    # Your project guide identifies \"Real\" as the positive class\n",
    "    y_raw = labels_df[LABEL_COLUMN].map({'Real': 1, 'Bogus': 0}).values\n",
    "    \n",
    "    # Check if all labels were mapped (i.e., no NaNs)\n",
    "    nan_count = np.isnan(y_raw).sum()\n",
    "    if nan_count > 0:\n",
    "        print(f\"Warning: {nan_count} labels were not 'Real' or 'Bogus' and are now NaN.\")\n",
    "        # For simplicity, we'll drop these rows with missing labels.\n",
    "        print(\"Dropping rows with missing labels...\")\n",
    "        X_raw = X_raw[~np.isnan(y_raw)]\n",
    "        y_raw = y_raw[~np.isnan(y_raw)]\n",
    "        \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"--- ERROR: File not found. ---\")\n",
    "    print(f\"Could not find: {e.filename}\")\n",
    "    print(\"Please make sure your 'dataset' folder is in the same directory as your 'FLARE.ipynb' notebook.\")\n",
    "    # Create tiny placeholder data so the notebook can still run for testing\n",
    "    X_raw = np.random.rand(10, 100, 100, 3) \n",
    "    y_raw = np.array([0,1,0,0,0,0,0,0,1,0])\n",
    "except KeyError as e:\n",
    "    print(f\"--- ERROR: Label column not found. ---\")\n",
    "    print(f\"Could not find column {e} in your CSV files.\")\n",
    "    print(f\"Please update the 'LABEL_COLUMN' variable in this cell if 'label' is incorrect.\")\n",
    "    # Create tiny placeholder data so the notebook can still run for testing\n",
    "    X_raw = np.random.rand(10, 100, 100, 3) \n",
    "    y_raw = np.array([0,1,0,0,0,0,0,0,1,0])\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "\n",
    "# --- 2. Process the data using your pipeline ---\n",
    "# The loaded .npy files are (N, 100, 100, 3)\n",
    "# The preprocessing functions (subtract_background, robust_scale_image)\n",
    "# are designed for 2D images. We must process each of the 3 channels individually.\n",
    "print(\"Processing real image data... (This may take a minute)\")\n",
    "TARGET_SIZE = (64, 64) # Target size from your project guide\n",
    "processed_triplets = []\n",
    "\n",
    "for i in range(len(X_raw)):\n",
    "    triplet = X_raw[i] # This is one (100, 100, 3) image\n",
    "    \n",
    "    # Separate the three channels (science, reference, difference)\n",
    "    sci_raw = triplet[:, :, 0]\n",
    "    ref_raw = triplet[:, :, 1]\n",
    "    diff_raw = triplet[:, :, 2]\n",
    "    \n",
    "    # Apply the full preprocessing pipeline (from Cell 2) to each 2D channel\n",
    "    sci_proc = resize_image(robust_scale_image(subtract_background(sci_raw)), TARGET_SIZE)\n",
    "    ref_proc = resize_image(robust_scale_image(subtract_background(ref_raw)), TARGET_SIZE)\n",
    "    diff_proc = resize_image(robust_scale_image(subtract_background(diff_raw)), TARGET_SIZE)\n",
    "    \n",
    "    # Re-stack the processed 2D channels back into a (64, 64, 3) triplet\n",
    "    processed_triplet = np.stack([sci_proc, ref_proc, diff_proc], axis=-1)\n",
    "    processed_triplets.append(processed_triplet)\n",
    "\n",
    "# Convert the list of processed images into a single NumPy array\n",
    "X = np.array(processed_triplets)\n",
    "y = np.array(y_raw).astype(int) # Ensure labels are integers\n",
    "\n",
    "print(f\"Data shape (X): {X.shape}\")\n",
    "print(f\"Labels shape (y): {y.shape}\")\n",
    "print(f\"Class distribution (0=Bogus, 1=Real): {np.bincount(y)}\")\n",
    "\n",
    "\n",
    "# --- 3. Create Stratified Splits ---\n",
    "# Use stratified sampling to maintain the same percentage of \"real\"/\"bogus\" in all splits\n",
    "# This is critical for imbalanced datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,       # 20% of data will be for the test set\n",
    "    random_state=42,     # For reproducible results\n",
    "    stratify=y           # Use labels for stratification\n",
    ")\n",
    "\n",
    "# Split the training data again to create a validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=0.2,       # 20% of the *remaining* 80% (i.e., 16% of total)\n",
    "    random_state=42,     \n",
    "    stratify=y_train     # Stratify again\n",
    ")\n",
    "\n",
    "print(f\"Train shapes: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Val shapes:   X={X_val.shape}, y={y_val.shape}\")\n",
    "print(f\"Test shapes:  X={X_test.shape}, y={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45770f87-ea9b-4904-8f3d-d46e241fc295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Method 1: Classical Baselines ---\n",
      "Flattened shape: (4617, 12288)\n",
      "Number of components chosen by PCA: 418\n",
      "Original feature dimension: 12288\n",
      "Reduced feature dimension: 418\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Method 1: Classical Baselines ---\")\n",
    "\n",
    "# 1. Flatten the images [cite: 232, 238]\n",
    "# Note: The guide [cite: 241-242] has a typo. This is the correct way to reshape.\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_val_flat = X_val.reshape(X_val.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "print(f\"Flattened shape: {X_train_flat.shape}\")\n",
    "\n",
    "# 2. Scale data before PCA [cite: 243-244]\n",
    "scaler_pca = StandardScaler()\n",
    "X_train_scaled = scaler_pca.fit_transform(X_train_flat) # [cite: 245]\n",
    "X_val_scaled = scaler_pca.transform(X_val_flat) # [cite: 246]\n",
    "X_test_scaled = scaler_pca.transform(X_test_flat) # [cite: 246]\n",
    "\n",
    "# 3. Apply PCA [cite: 247]\n",
    "# Choose n_components to explain 95% of variance [cite: 248]\n",
    "pca = PCA(n_components=0.95)\n",
    "# Fit PCA ONLY on the training data [cite: 249]\n",
    "pca.fit(X_train_scaled) # [cite: 249]\n",
    "print(f\"Number of components chosen by PCA: {pca.n_components_}\") # [cite: 250]\n",
    "\n",
    "# 4. Transform all datasets [cite: 251-252]\n",
    "X_train_pca = pca.transform(X_train_scaled)\n",
    "X_val_pca = pca.transform(X_val_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "print(f\"Original feature dimension: {X_train_flat.shape[1]}\") # [cite: 253]\n",
    "print(f\"Reduced feature dimension: {X_train_pca.shape[1]}\") # [cite: 254]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be81ee2c-37ef-4aa8-a973-f1e4b2766f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logistic Regression Performance ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       572\n",
      "           1       0.86      0.78      0.82       583\n",
      "\n",
      "    accuracy                           0.83      1155\n",
      "   macro avg       0.83      0.83      0.83      1155\n",
      "weighted avg       0.83      0.83      0.83      1155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "# Use class_weight='balanced' to handle imbalance\n",
    "lr_model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "lr_model.fit(X_train_pca, y_train) # [cite: 264]\n",
    "\n",
    "# Evaluate on the validation set\n",
    "y_val_pred_lr = lr_model.predict(X_val_pca)\n",
    "print(\"--- Logistic Regression Performance ---\")\n",
    "print(classification_report(y_val, y_val_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27dc54be-d418-43db-9149-9127c47e1585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Random Forest Performance ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       572\n",
      "           1       0.89      0.81      0.85       583\n",
      "\n",
      "    accuracy                           0.85      1155\n",
      "   macro avg       0.85      0.85      0.85      1155\n",
      "weighted avg       0.85      0.85      0.85      1155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "# Use class_weight='balanced' to handle imbalance [cite: 213, 273]\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    class_weight='balanced', # [cite: 273]\n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ") # [cite: 273-274]\n",
    "rf_model.fit(X_train_pca, y_train) # [cite: 274]\n",
    "\n",
    "# Evaluate on the validation set\n",
    "y_val_pred_rf = rf_model.predict(X_val_pca) # [cite: 275]\n",
    "print(\"--- Random Forest Performance ---\") # [cite: 275]\n",
    "print(classification_report(y_val, y_val_pred_rf)) # [cite: 276]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f12e1c42-e73b-41f1-aa1a-c9b36bff0809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CustomCNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"CustomCNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m1,048,704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,142,081</span> (4.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,142,081\u001b[0m (4.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,142,081</span> (4.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,142,081\u001b[0m (4.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "def build_custom_cnn(input_shape=(64, 64, 3), num_classes=1):\n",
    "    \"\"\"\n",
    "    Builds a custom CNN model.\n",
    "    \"\"\"\n",
    "    model = models.Sequential(name=\"CustomCNN\")\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    \n",
    "    # Block 1\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Block 2\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Block 3\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Classifier Head\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    \n",
    "    # Output layer\n",
    "    if num_classes == 1:\n",
    "        activation = 'sigmoid'\n",
    "        loss = 'binary_crossentropy'\n",
    "    else:\n",
    "        activation = 'softmax'\n",
    "        loss = 'categorical_crossentropy'\n",
    "        \n",
    "    model.add(layers.Dense(num_classes, activation=activation))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=loss,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example usage for binary classification\n",
    "cnn_model = build_custom_cnn(input_shape=(64, 64, 3), num_classes=1)\n",
    "cnn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63357734-2127-4647-ab5a-9cc9abb1cfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Method 2: Training Custom CNN ---\n",
      "Using class weights: {0: 1.010284463894967, 1: 0.9899228130360206}\n",
      "Epoch 1/5\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.6158 - loss: 1.5449 - val_accuracy: 0.6996 - val_loss: 0.5804\n",
      "Epoch 2/5\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.7966 - loss: 0.5199 - val_accuracy: 0.8563 - val_loss: 0.3536\n",
      "Epoch 3/5\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step - accuracy: 0.8527 - loss: 0.4036 - val_accuracy: 0.8442 - val_loss: 0.3117\n",
      "Epoch 4/5\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - accuracy: 0.8830 - loss: 0.3113 - val_accuracy: 0.8537 - val_loss: 0.3465\n",
      "Epoch 5/5\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.8969 - loss: 0.2757 - val_accuracy: 0.9177 - val_loss: 0.2520\n",
      "Custom CNN training complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Method 2: Training Custom CNN ---\")\n",
    "\n",
    "# Calculate class weights to handle imbalance\n",
    "weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = dict(enumerate(weights))\n",
    "print(f\"Using class weights: {class_weights_dict}\")\n",
    "\n",
    "# Create an augmented data pipeline\n",
    "# Apply augmentation only to the training data\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_ds = train_ds.shuffle(buffer_size=len(y_train))\n",
    "train_ds = train_ds.batch(32)\n",
    "train_ds = train_ds.map(lambda x, y: (data_augmentation_pipeline(x, training=True), y),\n",
    "                         num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Create validation dataset (no augmentation)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Train the model\n",
    "history_cnn = cnn_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=5,  # Use a small number for this demo\n",
    "    class_weight=class_weights_dict,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Custom CNN training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0219b5c-b90c-403a-9f6b-9c550eac7cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 1us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"TransferLearningModel\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"TransferLearningModel\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ get_item_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ get_item_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ stack (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Stack</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],            │\n",
       "│                               │                           │                 │ get_item_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
       "│                               │                           │                 │ get_item_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ stack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling2d      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ resnet50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ get_item (\u001b[38;5;33mGetItem\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ get_item_1 (\u001b[38;5;33mGetItem\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ get_item_2 (\u001b[38;5;33mGetItem\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ stack (\u001b[38;5;33mStack\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],            │\n",
       "│                               │                           │                 │ get_item_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
       "│                               │                           │                 │ get_item_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ stack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │      \u001b[38;5;34m23,587,712\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling2d      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ resnet50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ global_average_pooling2d[\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │           \u001b[38;5;34m2,049\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,589,761</span> (89.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,589,761\u001b[0m (89.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> (8.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,049\u001b[0m (8.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "def build_transfer_model(input_shape=(64, 64, 3), num_classes=1):\n",
    "    \"\"\"\n",
    "    Builds a transfer learning model using ResNet50.\n",
    "    \"\"\"\n",
    "    # 1. Load the pre-trained base model\n",
    "    base_model = tf.keras.applications.ResNet50(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # 2. Freeze the base model\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # 3. Add a custom classification head\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Preprocess inputs for ResNet\n",
    "    x = tf.keras.applications.resnet.preprocess_input(inputs)\n",
    "    \n",
    "    x = base_model(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    if num_classes == 1:\n",
    "        activation = 'sigmoid'\n",
    "    else:\n",
    "        activation = 'softmax'\n",
    "        \n",
    "    outputs = layers.Dense(num_classes, activation=activation)(x)\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"TransferLearningModel\")\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "transfer_model, base_model = build_transfer_model(input_shape=(64, 64, 3), num_classes=1)\n",
    "transfer_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de2cdf23-d2ac-41d7-8724-18cea65ae8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Method 3: Training Transfer Learning Model ---\n",
      "--- Phase 1: Training Head ---\n",
      "Epoch 1/3\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 238ms/step - accuracy: 0.7414 - loss: 0.7707 - val_accuracy: 0.8216 - val_loss: 0.4088\n",
      "Epoch 2/3\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 224ms/step - accuracy: 0.8183 - loss: 0.5579 - val_accuracy: 0.8580 - val_loss: 0.3743\n",
      "Epoch 3/3\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 257ms/step - accuracy: 0.8265 - loss: 0.5234 - val_accuracy: 0.8684 - val_loss: 0.3228\n",
      "--- Phase 2: Fine-Tuning ---\n",
      "Epoch 1/3\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 770ms/step - accuracy: 0.6117 - loss: 0.7822 - val_accuracy: 0.5879 - val_loss: 0.6616\n",
      "Epoch 2/3\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 738ms/step - accuracy: 0.7033 - loss: 0.6630 - val_accuracy: 0.7255 - val_loss: 0.5809\n",
      "Epoch 3/3\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 750ms/step - accuracy: 0.7637 - loss: 0.5707 - val_accuracy: 0.8087 - val_loss: 0.4827\n",
      "Transfer learning training complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Method 3: Training Transfer Learning Model ---\")\n",
    "\n",
    "# --- Phase 1: Train only the new head ---\n",
    "print(\"--- Phase 1: Training Head ---\")\n",
    "transfer_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_tl = transfer_model.fit(\n",
    "    train_ds,  # Using the augmented dataset from previous cells\n",
    "    validation_data=val_ds,\n",
    "    epochs=3,  # Train head for a few epochs\n",
    "    class_weight=class_weights_dict,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- Phase 2: Fine-Tuning ---\n",
    "print(\"--- Phase 2: Fine-Tuning ---\")\n",
    "# Unfreeze the base model (or top layers)\n",
    "base_model.trainable = True\n",
    "\n",
    "# Re-compile with a very low learning rate\n",
    "transfer_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_ft = transfer_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=3,  # Continue training\n",
    "    class_weight=class_weights_dict,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Transfer learning training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc9b9a35-cc38-4a45-8bdf-eab6238f558a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Method 4: Convolutional Autoencoder ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"autoencoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16384</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,640</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,121,219</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16384\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │       \u001b[38;5;34m1,048,640\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ decoder (\u001b[38;5;33mFunctional\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │       \u001b[38;5;34m1,121,219\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,189,251</span> (8.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,189,251\u001b[0m (8.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,189,251</span> (8.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,189,251\u001b[0m (8.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder on 2285 'bogus' images...\n",
      "Epoch 1/5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 108ms/step - loss: 7487.4370 - val_loss: 7625.7812\n",
      "Epoch 2/5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 103ms/step - loss: 7487.1221 - val_loss: 7625.6006\n",
      "Epoch 3/5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 102ms/step - loss: 7486.9854 - val_loss: 7625.5698\n",
      "Epoch 4/5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - loss: 7486.9131 - val_loss: 7626.0063\n",
      "Epoch 5/5\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - loss: 7486.7930 - val_loss: 7625.5542\n",
      "Autoencoder training complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Method 4: Convolutional Autoencoder ---\")\n",
    "\n",
    "# --- 1. Define the CAE Architecture ---\n",
    "latent_dim = 64\n",
    "input_shape = (64, 64, 3)\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = tf.keras.Input(shape=input_shape)\n",
    "x = layers.Conv2D(32, 3, activation='relu', padding='same')(encoder_inputs)\n",
    "x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "x = layers.Flatten()(x)\n",
    "encoder_outputs = layers.Dense(latent_dim, activation='relu')(x)\n",
    "encoder = tf.keras.Model(encoder_inputs, encoder_outputs, name=\"encoder\")\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = tf.keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(16 * 16 * 64, activation='relu')(decoder_inputs)\n",
    "x = layers.Reshape((16, 16, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D(2)(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D(2)(x)\n",
    "decoder_outputs = layers.Conv2D(3, 3, activation='sigmoid', padding='same')(x)\n",
    "decoder = tf.keras.Model(decoder_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "# Autoencoder\n",
    "autoencoder = tf.keras.Model(encoder_inputs, decoder(encoder_outputs), name=\"autoencoder\")\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "autoencoder.summary()\n",
    "\n",
    "# --- 2. Train the CAE ---\n",
    "# Train ONLY on \"bogus\" (normal) images\n",
    "X_train_bogus = X_train[y_train == 0]\n",
    "print(f\"Training autoencoder on {len(X_train_bogus)} 'bogus' images...\")\n",
    "\n",
    "# The input (x) and target (y) are the same images\n",
    "autoencoder.fit(\n",
    "    X_train_bogus, X_train_bogus,\n",
    "    epochs=5,  # Use small number for demo\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val[y_val == 0], X_val[y_val == 0]),  # Validate on bogus images\n",
    "    verbose=1\n",
    ")\n",
    "print(\"Autoencoder training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df06e9d-ec46-49d0-9bc1-d75983c82768",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
